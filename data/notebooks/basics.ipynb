{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = sqlContext.read.format(\"com.mongodb.spark.sql.DefaultSource\").load().cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+-------------------+---------+---------+---------+------------------+\n",
      "|      date|Missing points|Summed active power|WHRL1-ACC|WHRL2-ACC|WHRL3-ACC|Mean active energy|\n",
      "+----------+--------------+-------------------+---------+---------+---------+------------------+\n",
      "|2016-05-23|             8|               null|     null|     null|     null|              null|\n",
      "|2016-05-24|            69|             5.3115|   17.053|   17.032|   16.988|            51.073|\n",
      "|2016-05-25|            88|             5.3952|    4.906|      4.9|    4.903|            14.709|\n",
      "|2016-05-26|            96|               null|     null|     null|     null|              null|\n",
      "|2016-05-27|            64|              0.949|    3.798|    2.796|    2.782|             9.376|\n",
      "|2016-05-28|             1|             0.5617|    6.537|    4.829|    4.764|             16.13|\n",
      "|2016-05-29|             0|             0.6367|    7.541|    5.572|    5.474|            18.587|\n",
      "|2016-05-30|             1|             1.6248|   18.189|   13.604|    13.37|            45.163|\n",
      "|2016-05-31|             0|             1.0125|    11.89|    8.856|    8.692|            29.438|\n",
      "|2016-06-01|             0|             0.8896|    10.54|    7.841|    7.682|            26.063|\n",
      "+----------+--------------+-------------------+---------+---------+---------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from pyspark.sql.functions import udf, array, round, col\n",
    "from pyspark.sql.types import IntegerType, DateType, DoubleType,FloatType\n",
    "from datetime import datetime\n",
    "\n",
    "ref_date = datetime.strptime(\"2000-1-1\", \"%Y-%m-%d\")\n",
    "\n",
    "udf_convert_to_dt = udf(lambda i1, i2, i3: datetime.strptime(\"%s-%s-%s\" %(i1, i2, i3), \"%Y-%m-%d\"), returnType=DateType())\n",
    "udf_is_missing_data = udf(lambda element: 0 if element else 1, returnType=IntegerType())\n",
    "\n",
    "udf_to_date = udf(lambda item: datetime.strftime(item, \"%Y-%m-%d\"))\n",
    "\n",
    "\n",
    "data = df\\\n",
    "    .select(\n",
    "        col(\"serial_number\").alias(\"SN\"), \n",
    "        col(\"time\").alias(\"Time\"),\n",
    "        col(\"WL1.WL1-MEAN\").alias(\"WL1-MEAN\"),\n",
    "        col(\"WL2.WL2-MEAN\").alias(\"WL2-MEAN\"),\n",
    "        col(\"WL3.WL3-MEAN\").alias(\"WL3-MEAN\"),\n",
    "        col(\"WHRL1.WHRL1-ACC\").alias(\"WHRL1-ACC\"),\n",
    "        col(\"WHRL2.WHRL2-ACC\").alias(\"WHRL2-ACC\"),\n",
    "        col(\"WHRL3.WHRL3-ACC\").alias(\"WHRL3-ACC\")\n",
    "    )\\\n",
    "    .filter(df['time'] > ref_date)\\\n",
    "    .withColumn('missing', udf_is_missing_data('WL1-MEAN'))\\\n",
    "    .withColumn('date', udf_to_date(\"time\"))\\\n",
    "    .withColumn('WL-MEAN', col(\"WL1-MEAN\") + col(\"WL2-MEAN\") + col(\"WL3-MEAN\")/3)\\\n",
    "    .withColumn('WHRL-SUM', col(\"WHRL1-ACC\") + col(\"WHRL2-ACC\") + col(\"WHRL3-ACC\"))\\\n",
    "    .groupBy(\"date\")\\\n",
    "    .agg({\n",
    "        'WL1-MEAN': \"mean\", \n",
    "        'WL2-MEAN': \"mean\", \n",
    "        \"WL3-MEAN\": \"mean\", \n",
    "        \"missing\":\"sum\", \n",
    "        'WL-MEAN':'mean',\n",
    "        'WHRL1-ACC':'sum',\n",
    "        'WHRL2-ACC':'sum',\n",
    "        'WHRL3-ACC':'sum',\n",
    "        'WHRL-SUM':'sum'\n",
    "    })\\\n",
    "    .orderBy(\"date\")\\\n",
    "    .drop('Time')\\\n",
    "    .select(\n",
    "        'date', \n",
    "        col('sum(missing)').alias(\"Missing points\"),\n",
    "        #round(col('avg(WL1-MEAN)'), 4).alias('WL1-MEAN'),\n",
    "        #round(col('avg(WL2-MEAN)'), 4).alias('WL2-MEAN'),\n",
    "        #round(col('avg(WL3-MEAN)'), 4).alias('WL3-MEAN'),\n",
    "        round(col('avg(WL-MEAN)'), 4).alias('Summed active power'),\n",
    "        round(col('sum(WHRL1-ACC)'), 4).alias('WHRL1-ACC'),\n",
    "        round(col('sum(WHRL2-ACC)'), 4).alias('WHRL2-ACC'),\n",
    "        round(col('sum(WHRL3-ACC)'), 4).alias('WHRL3-ACC'),\n",
    "        round(col('sum(WHRL-SUM)'), 4).alias('Mean active energy')\n",
    "    )\n",
    "data.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
